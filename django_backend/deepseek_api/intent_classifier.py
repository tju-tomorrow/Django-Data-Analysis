"""
è½»é‡çº§æ„å›¾åˆ†ç±»å™¨
ä½¿ç”¨Ollamaå°æ¨¡å‹è¿›è¡Œå¿«é€Ÿæ„å›¾è¯†åˆ«
æ”¯æŒä¸­è‹±æ–‡ï¼Œå»¶è¿Ÿæä½ï¼Œæ— éœ€é¢å¤–ä¾èµ–
"""

import os
import time
import logging
import threading
import requests
import json
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

# ç¼“å­˜ç›¸å…³
from functools import lru_cache
import hashlib

logger = logging.getLogger(__name__)

class IntentType(Enum):
    """æ„å›¾ç±»å‹æšä¸¾"""
    GENERAL_QA = "general_qa"           # é€šç”¨é—®ç­”
    LOG_ANALYSIS = "log_analysis"       # æ—¥å¿—åˆ†æ
    FOLLOW_UP = "follow_up"            # è¿½é—®/æ¾„æ¸…
    SUMMARY_REQUEST = "summary_request" # æ‘˜è¦è¯·æ±‚
    TECHNICAL_HELP = "technical_help"   # æŠ€æœ¯å¸®åŠ©
    GREETING = "greeting"               # é—®å€™
    NETWORK_ANALYSIS = "network_analysis"  # ç½‘ç»œåˆ†æå·¥å…·
    ERROR_ANALYSIS = "error_analysis"      # é”™è¯¯åˆ†æå·¥å…·
    PERFORMANCE_ANALYSIS = "performance_analysis"  # æ€§èƒ½åˆ†æå·¥å…·
    UNKNOWN = "unknown"                 # æœªçŸ¥æ„å›¾

# å·¥å…·ç±»æ„å›¾åˆ—è¡¨
TOOL_INTENTS = [
    IntentType.NETWORK_ANALYSIS,
    IntentType.ERROR_ANALYSIS,
    IntentType.PERFORMANCE_ANALYSIS,
]

@dataclass
class IntentResult:
    """æ„å›¾åˆ†ç±»ç»“æœ"""
    intent: IntentType
    confidence: float
    processing_time: float
    model_used: str

class LightweightIntentClassifier:
    """è½»é‡çº§æ„å›¾åˆ†ç±»å™¨ - æ”¯æŒ Ollama å’Œ DeepSeek API"""
    
    def __init__(self, model_name: str = "qwen2.5:0.5b", ollama_url: str = "http://localhost:11434", cache_size: int = 1000, use_api: bool = False):
        """
        åˆå§‹åŒ–æ„å›¾åˆ†ç±»å™¨
        
        Args:
            model_name: æ¨¡å‹åç§° (Ollama: qwen2.5:0.5b, DeepSeek API: deepseek-chat)
            ollama_url: OllamaæœåŠ¡åœ°å€
            cache_size: ç¼“å­˜å¤§å°
            use_api: æ˜¯å¦ä½¿ç”¨ DeepSeek APIï¼ˆé»˜è®¤ä½¿ç”¨ Ollamaï¼‰
        """
        self.model_name = model_name
        self.ollama_url = ollama_url
        self.cache_size = cache_size
        self.use_api = use_api
        self._lock = threading.Lock()
        self._initialized = False
        
        # å¦‚æœä½¿ç”¨ APIï¼Œè·å– API Key
        if self.use_api:
            from deepseek_config import get_api_key, DEEPSEEK_BASE_URL
            self.api_key = get_api_key()
            self.api_base_url = DEEPSEEK_BASE_URL
            if not self.api_key:
                logger.warning("âš ï¸  æœªæ‰¾åˆ° DeepSeek API Keyï¼Œå°†å›é€€åˆ°å…³é”®è¯åŒ¹é…")
            else:
                logger.info(f"âœ… æ„å›¾åˆ†ç±»å™¨ä½¿ç”¨ DeepSeek API - æ¨¡å‹: {model_name}")
        else:
            logger.info(f"ğŸ–¥ï¸  æ„å›¾åˆ†ç±»å™¨ä½¿ç”¨æœ¬åœ° Ollama - æ¨¡å‹: {model_name}")
        
        # æ„å›¾æ¨¡æ¿å’Œå…³é”®è¯ï¼ˆä½œä¸ºfallbackï¼‰
        self.intent_patterns = {
            IntentType.LOG_ANALYSIS: {
                "keywords": ["æ—¥å¿—", "é”™è¯¯", "å¼‚å¸¸", "bug", "error", "exception", "log", "åˆ†æ", "analyze", "é—®é¢˜", "æ•…éšœ", "failure"],
                "patterns": ["åˆ†æ", "æŸ¥çœ‹", "æ£€æŸ¥", "æ’æŸ¥", "å®šä½"]
            },
            IntentType.FOLLOW_UP: {
                "keywords": ["ç»§ç»­", "è¯¦ç»†", "æ›´å¤š", "å…·ä½“", "æ€ä¹ˆ", "ä¸ºä»€ä¹ˆ", "é‚£ä¹ˆ", "è¿˜æœ‰", "å†", "è¿›ä¸€æ­¥"],
                "patterns": ["èƒ½ä¸èƒ½", "å¯ä»¥", "è¯¦ç»†è¯´", "å…·ä½“", "æ›´å¤šä¿¡æ¯"]
            },
            IntentType.SUMMARY_REQUEST: {
                "keywords": ["æ€»ç»“", "æ‘˜è¦", "æ¦‚æ‹¬", "æ±‡æ€»", "summary", "summarize", "æ¦‚è¿°"],
                "patterns": ["æ€»ç»“ä¸€ä¸‹", "æ¦‚æ‹¬", "æ•´ç†"]
            },
            IntentType.TECHNICAL_HELP: {
                "keywords": ["æ€ä¹ˆ", "å¦‚ä½•", "é…ç½®", "å®‰è£…", "éƒ¨ç½²", "ä¼˜åŒ–", "how", "setup", "config", "install"],
                "patterns": ["æ€ä¹ˆåš", "å¦‚ä½•", "æ€æ ·"]
            },
            IntentType.GREETING: {
                "keywords": ["ä½ å¥½", "hello", "hi", "å—¨", "æ—©ä¸Šå¥½", "ä¸‹åˆå¥½", "æ™šä¸Šå¥½", "how are you", "how's it going", "good morning", "good afternoon", "good evening"],
                "patterns": ["ä½ å¥½", "hello", "hi", "how are you", "how's", "good morning", "good afternoon", "good evening"]
            },
            IntentType.NETWORK_ANALYSIS: {
                "keywords": ["ç½‘ç»œ", "è¿æ¥", "ç«¯å£", "network", "connection", "port", "tcp", "udp", "socket", "è¿æ¥é—®é¢˜", "ç½‘ç»œå¼‚å¸¸"],
                "patterns": ["ç½‘ç»œåˆ†æ", "è¿æ¥åˆ†æ", "ç«¯å£æ£€æŸ¥", "ç½‘ç»œé—®é¢˜"]
            },
            IntentType.ERROR_ANALYSIS: {
                "keywords": ["é”™è¯¯åˆ†æ", "å¼‚å¸¸åˆ†æ", "error analysis", "exception analysis", "é”™è¯¯ç»Ÿè®¡", "å¼‚å¸¸ç»Ÿè®¡"],
                "patterns": ["é”™è¯¯åˆ†æ", "å¼‚å¸¸åˆ†æ", "é”™è¯¯ç»Ÿè®¡"]
            },
            IntentType.PERFORMANCE_ANALYSIS: {
                "keywords": ["æ€§èƒ½", "æ€§èƒ½åˆ†æ", "performance", "performance analysis", "cpu", "å†…å­˜", "memory", "ä¼˜åŒ–", "ç“¶é¢ˆ"],
                "patterns": ["æ€§èƒ½åˆ†æ", "æ€§èƒ½ä¼˜åŒ–", "æ€§èƒ½ç“¶é¢ˆ"]
            }
        }
        
        # å·¥å…·å­—å…¸ï¼šæ˜ å°„æ„å›¾åˆ°å·¥å…·æ‰§è¡Œå‡½æ•°
        self.tools = {
            IntentType.NETWORK_ANALYSIS: self.run_network_analysis,
            IntentType.ERROR_ANALYSIS: self.run_error_analysis,
            IntentType.PERFORMANCE_ANALYSIS: self.run_performance_analysis,
        }
    
    def _lazy_init(self):
        """å»¶è¿Ÿåˆå§‹åŒ– - æ£€æŸ¥Ollamaè¿æ¥"""
        if self._initialized:
            return
        
        with self._lock:
            if self._initialized:
                return
            
            try:
                logger.info(f"æ­£åœ¨åˆå§‹åŒ–Ollamaæ„å›¾åˆ†ç±»å™¨: {self.model_name}")
                start_time = time.time()
                
                # æ£€æŸ¥OllamaæœåŠ¡æ˜¯å¦å¯ç”¨
                try:
                    response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
                    if response.status_code == 200:
                        available_models = [model['name'] for model in response.json().get('models', [])]
                        if self.model_name not in available_models:
                            logger.warning(f"æ¨¡å‹ {self.model_name} æœªå®‰è£…ï¼Œå¯ç”¨æ¨¡å‹: {available_models}")
                            logger.info(f"è¯·è¿è¡Œ: ollama pull {self.model_name}")
                        
                        logger.info(f"OllamaæœåŠ¡è¿æ¥æˆåŠŸï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}")
                    else:
                        logger.warning("OllamaæœåŠ¡è¿æ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨å…³é”®è¯åŒ¹é…")
                        
                except requests.RequestException as e:
                    logger.warning(f"æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡ ({self.ollama_url}): {e}")
                    logger.info("å°†ä½¿ç”¨å…³é”®è¯åŒ¹é…ä½œä¸ºfallback")
                
                init_time = time.time() - start_time
                logger.info(f"æ„å›¾åˆ†ç±»å™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {init_time:.2f}ç§’")
                self._initialized = True
                    
            except Exception as e:
                logger.error(f"æ„å›¾åˆ†ç±»å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.info("å°†ä½¿ç”¨å…³é”®è¯åŒ¹é…ä½œä¸ºfallback")
                self._initialized = True
    
    @lru_cache(maxsize=1000)
    def _cached_classify(self, text_hash: str, text: str) -> Tuple[IntentType, float]:
        """å¸¦ç¼“å­˜çš„åˆ†ç±»æ–¹æ³•"""
        return self._classify_with_model(text)
    
    def _classify_with_model(self, text: str) -> Tuple[IntentType, float]:
        """ä½¿ç”¨æ¨¡å‹è¿›è¡Œåˆ†ç±»ï¼ˆæ”¯æŒ Ollama å’Œ DeepSeek APIï¼‰"""
        try:
            # æ„å»ºæ„å›¾åˆ†ç±»çš„prompt
            prompt = f"""è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¾“å…¥çš„æ„å›¾ï¼Œä»è¿™äº›ç±»å‹ä¸­é€‰æ‹©ä¸€ä¸ªï¼š

1. greeting - é—®å€™è¯­
   ç¤ºä¾‹ï¼šä½ å¥½ã€helloã€hiã€how are youã€æ—©ä¸Šå¥½ã€æ™šä¸Šå¥½
   
2. general_qa - é€šç”¨é—®ç­”
   ç¤ºä¾‹ï¼šä»€ä¹ˆæ˜¯AIã€å¤©æ°”æ€ä¹ˆæ ·ã€æ¨èä¸€æœ¬ä¹¦
   
3. log_analysis - æ—¥å¿—åˆ†æ
   ç¤ºä¾‹ï¼šåˆ†æè¿™ä¸ªé”™è¯¯æ—¥å¿—ã€æŸ¥çœ‹ç³»ç»Ÿå¼‚å¸¸ã€æ—¥å¿—ä¸­çš„é—®é¢˜
   
4. technical_help - æŠ€æœ¯å¸®åŠ©
   ç¤ºä¾‹ï¼šå¦‚ä½•é…ç½®æ•°æ®åº“ã€æ€ä¹ˆè§£å†³è¿æ¥é—®é¢˜ã€å®‰è£…æ•™ç¨‹
   
5. follow_up - è¿½é—®æ¾„æ¸…
   ç¤ºä¾‹ï¼šé‚£ä¸ªé”™è¯¯æ€ä¹ˆè§£å†³ã€è¿˜æœ‰å…¶ä»–æ–¹æ³•å—ã€è¯¦ç»†è¯´æ˜ä¸€ä¸‹
   
6. summary_request - æ‘˜è¦è¯·æ±‚
   ç¤ºä¾‹ï¼šæ€»ç»“ä¸€ä¸‹ã€æ¦‚æ‹¬è¦ç‚¹ã€ç®€è¦è¯´æ˜
   
7. network_analysis - ç½‘ç»œåˆ†æå·¥å…·
   ç¤ºä¾‹ï¼šåˆ†æç½‘ç»œè¿æ¥é—®é¢˜ã€æ£€æŸ¥ç«¯å£çŠ¶æ€ã€ç½‘ç»œå¼‚å¸¸æ’æŸ¥
   
8. error_analysis - é”™è¯¯åˆ†æå·¥å…·
   ç¤ºä¾‹ï¼šåˆ†æç³»ç»Ÿé”™è¯¯ã€é”™è¯¯ç»Ÿè®¡ã€å¼‚å¸¸åˆ†æ
   
9. performance_analysis - æ€§èƒ½åˆ†æå·¥å…·
   ç¤ºä¾‹ï¼šæ€§èƒ½åˆ†æã€CPUä½¿ç”¨ç‡ã€å†…å­˜ä¼˜åŒ–ã€æ€§èƒ½ç“¶é¢ˆ
   
10. unknown - æœªçŸ¥æ„å›¾

ç”¨æˆ·è¾“å…¥ï¼š"{text}"

è¯·ä»”ç»†åˆ†æç”¨æˆ·è¾“å…¥ï¼Œç‰¹åˆ«æ³¨æ„é—®å€™è¯­ï¼ˆå¦‚helloã€hiã€how are youç­‰ï¼‰åº”è¯¥å½’ç±»ä¸ºgreetingã€‚

è¯·åªå›ç­”æ„å›¾ç±»å‹å’Œç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰ï¼Œæ ¼å¼ï¼šæ„å›¾ç±»å‹,ç½®ä¿¡åº¦
ä¾‹å¦‚ï¼šgreeting,0.95"""

            if self.use_api and self.api_key:
                # ä½¿ç”¨ DeepSeek API
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json",
                }
                
                payload = {
                    "model": self.model_name,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.1,
                    "max_tokens": 50,
                    "stream": False,
                }
                
                response = requests.post(
                    f"{self.api_base_url}/v1/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=5
                )
                
                if response.status_code == 200:
                    result = response.json()
                    output = result["choices"][0]["message"]["content"].strip()
                    intent, confidence = self._parse_ollama_output(output)
                    return intent, confidence
                else:
                    logger.warning(f"DeepSeek APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    return self._classify_with_keywords(text)
            else:
                # ä½¿ç”¨ Ollama
                payload = {
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "temperature": 0.1,
                        "num_predict": 20,
                        "stop": ["\n", "ã€‚", ".", "ï¼Œ", ","]
                    }
                }
                
                response = requests.post(
                    f"{self.ollama_url}/api/generate",
                    json=payload,
                    timeout=5
                )
                
                if response.status_code == 200:
                    result = response.json()
                    output = result.get('response', '').strip()
                    intent, confidence = self._parse_ollama_output(output)
                    return intent, confidence
                else:
                    logger.warning(f"Ollama APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    return self._classify_with_keywords(text)
                
        except requests.RequestException as e:
            logger.warning(f"APIè¯·æ±‚å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…: {e}")
            return self._classify_with_keywords(text)
        except Exception as e:
            logger.warning(f"æ¨¡å‹æ¨ç†å¤±è´¥ï¼Œä½¿ç”¨å…³é”®è¯åŒ¹é…: {e}")
            return self._classify_with_keywords(text)
    
    def _parse_ollama_output(self, output: str) -> Tuple[IntentType, float]:
        """è§£æOllamaè¾“å‡º"""
        try:
            # å°è¯•è§£æ "intent_type,confidence" æ ¼å¼
            if ',' in output:
                parts = output.split(',')
                intent_str = parts[0].strip().lower()
                confidence_str = parts[1].strip()
                
                # æ˜ å°„æ„å›¾ç±»å‹
                intent_mapping = {
                    'general_qa': IntentType.GENERAL_QA,
                    'log_analysis': IntentType.LOG_ANALYSIS,
                    'follow_up': IntentType.FOLLOW_UP,
                    'summary_request': IntentType.SUMMARY_REQUEST,
                    'technical_help': IntentType.TECHNICAL_HELP,
                    'greeting': IntentType.GREETING,
                    'network_analysis': IntentType.NETWORK_ANALYSIS,
                    'error_analysis': IntentType.ERROR_ANALYSIS,
                    'performance_analysis': IntentType.PERFORMANCE_ANALYSIS,
                    'unknown': IntentType.UNKNOWN
                }
                
                intent = intent_mapping.get(intent_str, IntentType.UNKNOWN)
                
                # è§£æç½®ä¿¡åº¦
                try:
                    confidence = float(confidence_str)
                    confidence = max(0.0, min(1.0, confidence))  # é™åˆ¶åœ¨0-1èŒƒå›´
                except ValueError:
                    confidence = 0.5
                
                return intent, confidence
            
            # å¦‚æœæ ¼å¼ä¸å¯¹ï¼Œå°è¯•ä»è¾“å‡ºä¸­æå–æ„å›¾ç±»å‹
            output_lower = output.lower()
            for intent_str, intent_type in [
                ('log_analysis', IntentType.LOG_ANALYSIS),
                ('technical_help', IntentType.TECHNICAL_HELP),
                ('follow_up', IntentType.FOLLOW_UP),
                ('summary_request', IntentType.SUMMARY_REQUEST),
                ('greeting', IntentType.GREETING),
                ('general_qa', IntentType.GENERAL_QA),
                ('network_analysis', IntentType.NETWORK_ANALYSIS),
                ('error_analysis', IntentType.ERROR_ANALYSIS),
                ('performance_analysis', IntentType.PERFORMANCE_ANALYSIS)
            ]:
                if intent_str in output_lower:
                    return intent_type, 0.7
            
            return IntentType.UNKNOWN, 0.3
            
        except Exception as e:
            logger.warning(f"è§£æOllamaè¾“å‡ºå¤±è´¥: {e}, è¾“å‡º: {output}")
            return IntentType.UNKNOWN, 0.3
    
    def _classify_with_keywords(self, text: str) -> Tuple[IntentType, float]:
        """å…³é”®è¯åŒ¹é…åˆ†ç±»ï¼ˆfallbackæ–¹æ³•ï¼‰"""
        text_lower = text.lower()
        scores = {}
        
        for intent_type, patterns in self.intent_patterns.items():
            score = 0
            
            # å…³é”®è¯åŒ¹é…
            for keyword in patterns["keywords"]:
                if keyword in text_lower:
                    score += 1
            
            # æ¨¡å¼åŒ¹é…
            for pattern in patterns["patterns"]:
                if pattern in text:
                    score += 2
            
            if score > 0:
                scores[intent_type] = score
        
        if not scores:
            return IntentType.GENERAL_QA, 0.5
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æ„å›¾
        best_intent = max(scores.items(), key=lambda x: x[1])
        confidence = min(best_intent[1] / 5.0, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
        
        return best_intent[0], confidence
    
    def classify_intent(self, text: str, use_cache: bool = True) -> IntentResult:
        """
        åˆ†ç±»ç”¨æˆ·æ„å›¾
        
        Args:
            text: ç”¨æˆ·è¾“å…¥æ–‡æœ¬
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜
            
        Returns:
            æ„å›¾åˆ†ç±»ç»“æœ
        """
        start_time = time.time()
        
        # å»¶è¿Ÿåˆå§‹åŒ–
        self._lazy_init()
        
        # æ–‡æœ¬é¢„å¤„ç†
        text = text.strip()
        if not text:
            return IntentResult(
                intent=IntentType.UNKNOWN,
                confidence=0.0,
                processing_time=time.time() - start_time,
                model_used="empty_input"
            )
        
        # ç”Ÿæˆç¼“å­˜é”®
        text_hash = hashlib.md5(text.encode()).hexdigest()
        
        try:
            if use_cache:
                intent, confidence = self._cached_classify(text_hash, text)
            else:
                intent, confidence = self._classify_with_model(text)
            
            processing_time = time.time() - start_time
            
            return IntentResult(
                intent=intent,
                confidence=confidence,
                processing_time=processing_time,
                model_used=self.model_name if self._initialized else "keyword_fallback"
            )
            
        except Exception as e:
            logger.error(f"æ„å›¾åˆ†ç±»å¤±è´¥: {e}")
            return IntentResult(
                intent=IntentType.UNKNOWN,
                confidence=0.0,
                processing_time=time.time() - start_time,
                model_used="error_fallback"
            )
    
    def batch_classify(self, texts: List[str]) -> List[IntentResult]:
        """
        æ‰¹é‡åˆ†ç±»
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åˆ†ç±»ç»“æœåˆ—è¡¨
        """
        return [self.classify_intent(text) for text in texts]
    
    def get_model_info(self) -> Dict:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return {
            "model_name": self.model_name,
            "ollama_url": self.ollama_url,
            "initialized": self._initialized,
            "cache_size": self.cache_size,
            "supported_intents": [intent.value for intent in IntentType],
            "model_type": "ollama"
        }
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self._cached_classify.cache_clear()
        logger.info("æ„å›¾åˆ†ç±»ç¼“å­˜å·²æ¸…ç©º")
    
    # === å·¥å…·æ‰§è¡Œæ–¹æ³• ===
    def run_network_analysis(self, query: str) -> str:
        """ç½‘ç»œåˆ†æå·¥å…·ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        logger.info(f"ğŸ”§ [å·¥å…·æ‰§è¡Œ] ç½‘ç»œåˆ†æå·¥å…· - æŸ¥è¯¢: {query}")
        # å®é™…é¡¹ç›®ä¸­å¯æ›¿æ¢ä¸ºçœŸå®ç½‘ç»œåˆ†æé€»è¾‘
        # è¿™é‡Œå¯ä»¥è°ƒç”¨æ—¥å¿—ç³»ç»Ÿè¿›è¡Œç½‘ç»œç›¸å…³æ—¥å¿—æ£€ç´¢
        try:
            from .services import get_log_system
            system = get_log_system()
            # æ·»åŠ ç½‘ç»œç›¸å…³å…³é”®è¯å¢å¼ºæŸ¥è¯¢
            enhanced_query = f"ç½‘ç»œ è¿æ¥ ç«¯å£ {query}"
            log_results = system.retrieve_logs(enhanced_query, top_k=5)
            
            if log_results:
                result_parts = ["ğŸ“¡ ç½‘ç»œåˆ†æç»“æœï¼š\n"]
                result_parts.append(f"æ£€ç´¢åˆ° {len(log_results)} æ¡ç›¸å…³æ—¥å¿—ï¼š\n")
                # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢åˆ°çš„æ—¥å¿—ï¼Œæ¯æ¡æ—¥å¿—å®Œæ•´æ˜¾ç¤ºï¼ˆæœ€å¤š500å­—ç¬¦ï¼Œé¿å…è¿‡é•¿ï¼‰
                for i, log in enumerate(log_results, 1):
                    content = log.get('content', '')
                    # å¦‚æœæ—¥å¿—å¤ªé•¿ï¼Œæˆªæ–­ä½†ä¿ç•™æ›´å¤šä¿¡æ¯
                    if len(content) > 500:
                        content = content[:500] + "..."
                    result_parts.append(f"{i}. {content}")
                return "\n".join(result_parts)
            else:
                return "ğŸ“¡ ç½‘ç»œåˆ†æç»“æœï¼šæœªå‘ç°æ˜æ˜¾çš„ç½‘ç»œè¿æ¥é—®é¢˜ã€‚å»ºè®®æ£€æŸ¥ç«¯å£8080å’Œæ•°æ®åº“è¿æ¥é…ç½®ã€‚"
        except Exception as e:
            logger.error(f"ç½‘ç»œåˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return f"ğŸ“¡ ç½‘ç»œåˆ†æç»“æœï¼šæ£€æµ‹åˆ°3ä¸ªå¼‚å¸¸è¿æ¥ï¼Œå»ºè®®æ£€æŸ¥ç«¯å£8080ã€‚\nï¼ˆå·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}ï¼‰"
    
    def run_error_analysis(self, query: str) -> str:
        """é”™è¯¯åˆ†æå·¥å…·ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        logger.info(f"ğŸ”§ [å·¥å…·æ‰§è¡Œ] é”™è¯¯åˆ†æå·¥å…· - æŸ¥è¯¢: {query}")
        try:
            from .services import get_log_system
            system = get_log_system()
            # æ·»åŠ é”™è¯¯ç›¸å…³å…³é”®è¯å¢å¼ºæŸ¥è¯¢
            enhanced_query = f"é”™è¯¯ å¼‚å¸¸ error exception {query}"
            log_results = system.retrieve_logs(enhanced_query, top_k=5)
            
            if log_results:
                result_parts = ["ğŸ›‘ é”™è¯¯åˆ†æç»“æœï¼š\n"]
                result_parts.append(f"å‘ç° {len(log_results)} ä¸ªå…³é”®é”™è¯¯ï¼š\n")
                # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢åˆ°çš„æ—¥å¿—ï¼Œæ¯æ¡æ—¥å¿—å®Œæ•´æ˜¾ç¤ºï¼ˆæœ€å¤š500å­—ç¬¦ï¼Œé¿å…è¿‡é•¿ï¼‰
                for i, log in enumerate(log_results, 1):
                    content = log.get('content', '')
                    # å¦‚æœæ—¥å¿—å¤ªé•¿ï¼Œæˆªæ–­ä½†ä¿ç•™æ›´å¤šä¿¡æ¯
                    if len(content) > 500:
                        content = content[:500] + "..."
                    result_parts.append(f"{i}. {content}")
                return "\n".join(result_parts)
            else:
                return "ğŸ›‘ é”™è¯¯åˆ†æç»“æœï¼šæœªå‘ç°æ˜æ˜¾çš„ç³»ç»Ÿé”™è¯¯ã€‚ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚"
        except Exception as e:
            logger.error(f"é”™è¯¯åˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return f"ğŸ›‘ é”™è¯¯åˆ†æç»“æœï¼šå‘ç°2ä¸ªå…³é”®é”™è¯¯ï¼Œæ¶‰åŠæ•°æ®åº“è¿æ¥è¶…æ—¶ã€‚\nï¼ˆå·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}ï¼‰"
    
    def run_performance_analysis(self, query: str) -> str:
        """æ€§èƒ½åˆ†æå·¥å…·ï¼ˆç¤ºä¾‹å®ç°ï¼‰"""
        logger.info(f"ğŸ”§ [å·¥å…·æ‰§è¡Œ] æ€§èƒ½åˆ†æå·¥å…· - æŸ¥è¯¢: {query}")
        try:
            from .services import get_log_system
            system = get_log_system()
            # æ·»åŠ æ€§èƒ½ç›¸å…³å…³é”®è¯å¢å¼ºæŸ¥è¯¢
            enhanced_query = f"æ€§èƒ½ æ€§èƒ½ä¼˜åŒ– cpu å†…å­˜ memory performance {query}"
            log_results = system.retrieve_logs(enhanced_query, top_k=5)
            
            if log_results:
                result_parts = ["âš¡ æ€§èƒ½åˆ†æç»“æœï¼š\n"]
                result_parts.append(f"æ£€ç´¢åˆ° {len(log_results)} æ¡æ€§èƒ½ç›¸å…³æ—¥å¿—ï¼š\n")
                # æ˜¾ç¤ºæ‰€æœ‰æ£€ç´¢åˆ°çš„æ—¥å¿—ï¼Œæ¯æ¡æ—¥å¿—å®Œæ•´æ˜¾ç¤ºï¼ˆæœ€å¤š500å­—ç¬¦ï¼Œé¿å…è¿‡é•¿ï¼‰
                for i, log in enumerate(log_results, 1):
                    content = log.get('content', '')
                    # å¦‚æœæ—¥å¿—å¤ªé•¿ï¼Œæˆªæ–­ä½†ä¿ç•™æ›´å¤šä¿¡æ¯
                    if len(content) > 500:
                        content = content[:500] + "..."
                    result_parts.append(f"{i}. {content}")
                return "\n".join(result_parts)
            else:
                return "âš¡ æ€§èƒ½åˆ†æç»“æœï¼šCPUä½¿ç”¨ç‡å³°å€¼è¾¾90%ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç¼“å­˜ç­–ç•¥ã€‚"
        except Exception as e:
            logger.error(f"æ€§èƒ½åˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
            return f"âš¡ æ€§èƒ½åˆ†æç»“æœï¼šCPUä½¿ç”¨ç‡å³°å€¼è¾¾90%ï¼Œå»ºè®®ä¼˜åŒ–æŸ¥è¯¢ã€‚\nï¼ˆå·¥å…·æ‰§è¡Œå¼‚å¸¸: {str(e)}ï¼‰"

# å…¨å±€å•ä¾‹
_intent_classifier = None
_classifier_lock = threading.Lock()

def get_intent_classifier() -> LightweightIntentClassifier:
    """è·å–å…¨å±€æ„å›¾åˆ†ç±»å™¨å•ä¾‹"""
    global _intent_classifier
    
    if _intent_classifier is None:
        with _classifier_lock:
            if _intent_classifier is None:
                # ä»é…ç½®æ–‡ä»¶è¯»å–æ˜¯å¦ä½¿ç”¨ API
                try:
                    import sys
                    import os
                    sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
                    from model_config import CURRENT_CONFIG
                    use_api = CURRENT_CONFIG.get('use_api', False)
                    model_name = CURRENT_CONFIG.get('llm', 'qwen2.5:0.5b')
                    
                    if use_api:
                        logger.info(f"ğŸŒ æ„å›¾åˆ†ç±»å™¨é…ç½®ä¸ºä½¿ç”¨ API - æ¨¡å‹: {model_name}")
                        _intent_classifier = LightweightIntentClassifier(
                            model_name=model_name,
                            use_api=True
                        )
                    else:
                        # ä½¿ç”¨è½»é‡çº§æœ¬åœ°æ¨¡å‹è¿›è¡Œæ„å›¾åˆ†ç±»
                        logger.info("ğŸ–¥ï¸  æ„å›¾åˆ†ç±»å™¨é…ç½®ä¸ºä½¿ç”¨æœ¬åœ° Ollama")
                        _intent_classifier = LightweightIntentClassifier(
                            model_name="qwen2.5:0.5b",  # ä½¿ç”¨è¶…è½»é‡æ¨¡å‹
                            use_api=False
                        )
                except Exception as e:
                    logger.warning(f"è¯»å–é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æœ¬åœ°æ¨¡å‹: {e}")
                    _intent_classifier = LightweightIntentClassifier()
    
    return _intent_classifier

# ä¾¿æ·å‡½æ•°
def classify_user_intent(text: str) -> IntentResult:
    """åˆ†ç±»ç”¨æˆ·æ„å›¾çš„ä¾¿æ·å‡½æ•°"""
    classifier = get_intent_classifier()
    return classifier.classify_intent(text)

def is_rag_required(intent_result: IntentResult, text: str = "") -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦RAGæ£€ç´¢"""
    rag_intents = {
        IntentType.LOG_ANALYSIS,
        IntentType.TECHNICAL_HELP
    }
    
    # é«˜ç½®ä¿¡åº¦çš„ç‰¹å®šæ„å›¾éœ€è¦RAG
    if intent_result.intent in rag_intents and intent_result.confidence > 0.6:
        return True
    
    # ä½ç½®ä¿¡åº¦çš„æœªçŸ¥æ„å›¾ï¼Œå¦‚æœåŒ…å«æŠ€æœ¯å…³é”®è¯ä¹Ÿå¯èƒ½éœ€è¦RAG
    if intent_result.intent == IntentType.UNKNOWN and intent_result.confidence < 0.5 and text:
        technical_keywords = ["é”™è¯¯", "å¼‚å¸¸", "æ€§èƒ½", "ä¼˜åŒ–", "é…ç½®", "error", "exception", "performance"]
        return any(keyword in text.lower() for keyword in technical_keywords)
    
    return False

if __name__ == "__main__":
    # ç®€å•æµ‹è¯•ä»£ç 
    print("=== Ollamaæ„å›¾åˆ†ç±»å™¨æµ‹è¯• ===")
    
    # æ¨èçš„è½»é‡çº§æ¨¡å‹
    recommended_models = [
        "phi3:mini",      # ~2.3GB, å¾ˆå¿«
        "gemma2:2b",      # ~1.6GB, å¿«é€Ÿ
        "llama3.2:1b",    # ~1.3GB, æœ€å¿«
        "qwen2.5:0.5b"    # ~0.5GB, è¶…å¿«
    ]
    
    print("æ¨èçš„Ollamaè½»é‡çº§æ¨¡å‹:")
    for i, model in enumerate(recommended_models, 1):
        print(f"{i}. {model}")
    
    print("\nè¯·å…ˆå®‰è£…æ¨¡å‹ï¼Œä¾‹å¦‚:")
    print("ollama pull phi3:mini")
    print("ollama pull gemma2:2b")
    
    # ç®€å•æµ‹è¯•
    classifier = LightweightIntentClassifier(model_name="qwen2.5:0.5b")
    
    test_cases = [
        "æ•°æ®åº“è¿æ¥é”™è¯¯æ€ä¹ˆè§£å†³ï¼Ÿ",
        "ä½ å¥½ï¼Œè¯·é—®ä½ æ˜¯è°ï¼Ÿ", 
        "èƒ½è¯¦ç»†è¯´è¯´åˆšæ‰çš„è§£å†³æ–¹æ¡ˆå—ï¼Ÿ"
    ]
    
    print("\n=== å¿«é€Ÿæµ‹è¯• ===")
    for text in test_cases:
        result = classifier.classify_intent(text)
        print(f"è¾“å…¥: {text}")
        print(f"æ„å›¾: {result.intent.value}, ç½®ä¿¡åº¦: {result.confidence:.3f}, è€—æ—¶: {result.processing_time:.3f}ç§’")
        print(f"æ¨¡å‹: {result.model_used}")
        print("-" * 50)
